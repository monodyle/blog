---
title: Stay aware of AI generated content
excerpt: The Matrix is ​​at its most insane patch right now
date: Nov 30, 2025
tags: [ai]
public: false
---

On November 18, [Gemini 3 was released][gemini-3-released], and just two days later
[Nano Banana Pro drop][nano-banana-drop]. The internet went crazy, at least on my feed. One tweet
alone hit 75 million views on X, follow up with a lot of memes and jokes mixing AI-generated images
with the realistic ones. Honestly, it's pretty fun, but also scares me a little at the same time.

[gemini-3-released]: https://blog.google/products/gemini/gemini-3/
[nano-banana-drop]: https://blog.google/technology/ai/nano-banana-pro/

![https://x.com/immasiddx/status/1992979078220263720](/assets/notes/stay-aware-of-ai-generated-content/immasiddx-tweet.png)
*https://x.com/immasiddx/status/1992979078220263720*

Year ago, my friend showed me a video of some disaster from nowhere on earth, the whole video looked
off, it's violate the physics, the movement didn't make any sense. I immediately told him, "That's
an AI video. How does this kind of video fool you? What a stupid ass!".

A year later, I'm getting confused by AI videos. Some of them look too instantly tell it's
generated. The physic, the movement, the expressions, everything become much more believable and
getting better in just one year. Or maybe, I'm just being a stupid ass too!

## Generated content getting real

https://youtu.be/8a5y8Hm0yYk

Watch this experiment from the ABC[^1], where BTN High showed four high school students 21 videos
and asked them to decide if they were real or AI.

[^1]: [Australian Broadcasting Corporation](https://en.wikipedia.org/wiki/Australian_Broadcasting_Corporation)

The students were fooled by most of the videos. Not suprising, since people today watch so many
short-form videos that caused a short attention. So if we not trying to paying close attention, or
looking close into details, the AI video can easily trick us.

I was confused about the given videos too, I had to replay several clips multiple times before
realized it's AI video. From my experiment, AI videos today are enough to fool most non-tech-savvy
people. Sure, some of you can tell it's easy to spot the fault of generated content at the moment,
but with the exponential growth of this industry, the generated content is getting better and
better, not being perfect, but pretty soon it'll beat us one by one.

Part of society is scaring of generated content getting more realistic. They even doubt beautiful
things that existed before AI appeared—the em dash I love has become the focus of criticism, sadly.

> “In recent months, a curious fixation has emerged in corners of academia: the em dash. More
> specifically, the apparent moral panic around how it is spaced. A dash with no spaces on either
> side? That must be AI-generated writing. Case closed.”
>
> — Joseph Mellors, [Inside Higher Ed](https://www.insidehighered.com/opinion/views/2025/06/20/whats-em-dashai-anxieties-opinion)

People was made AI content detection tools, by trying to find a pattern, detect common words using
by AI, how predictable, the variance, and perplexity of the content. For images, they finding for
texture artifact, unnatural edges, GAN fingerprint. But most of them not really works, or
reaching limitation, some get cheating by a lot workaround solutions.

## SynthID

Lucky that, SynthID[^2] is a big shift in protecting humanity from the downsides of generated
content.

[^2]: Identifying AI-generated images with SynthID (https://deepmind.google/notes/identifying-ai-generated-images-with-synthid/)

I know it's still new and needs time to be battle tested. We've got a long road ahead, but it's a
good start.

Nano Banana Pro is the most realistic model so far, but it's also a easiest one to being detected.
You can upload the image and ask Gemini whether it's generated image, Gemini will run
SynthID and check if the image generated by Google's Nano Banana model.

![I asked Gemini if the image on top of this article is generated content](/assets/notes/stay-aware-of-ai-generated-content/synthid-in-gemini.png)
*I asked Gemini if the image on top of this article is generated content*

Of course, it doesn't work for Seedream, Midjourney, Qwen-Image, or any other image-generation
models, but Nano Banana. Hopefully, one day we'll have an unified tool can detect them all.

## How SynthID works?

I'm dive a little into how SynthID work and it's quite interesting for me, so I decide to write this
article.

> SynthID embeds digital watermarks directly into AI-generated images, audio, text or video. The
> watermarks are embedded across Google’s generative AI consumer products, and are imperceptible to
> humans – but can be detected by SynthID's technology.
>
> ...
>
> SynthID adds an invisible digital watermark to an AI-generated image (or video segment). The
> watermark doesn’t change the image or video quality. It’s added the moment content is created, and
> designed to stand up to modifications like cropping, adding filters, changing frame rates, or
> lossy compression.

When I see the "watermark", it's not the overlay stamped on top of the media as I known. So I found,
in terms of watermark, it's a faint design made in some paper during manufacture that is visible
when held against the light and typically identifies the maker. Yeah so it's completely invisible,
but how?

Initially, I thought they modified pixel, add a litle modified to the RGB pixel, and turn it into a
pattern. So the algorithm can run and find out if it is the watermark. But its so easy to be
removed, by cropping, adjust the color, or resize image. So it *can't be just* modify the pixel.

On the Google's blog, they train a deep learning model to identifying the watermark together with
the generated one. So even though the watermark is added to the generation process, but the encoder
network can ultimately outputs a real image with a tiny pixel-level adjustment.

![The changes is very subtle](/assets/notes/stay-aware-of-ai-generated-content/encoder-network.svg)
*The changes is very subtle*

This method allows watermark can survive even if the image is transformed or converted to other
compressing format. By trained to be robust, not fragile. The encoder and decoder exposed to a huge
variety of transformations that they expect to be readily available on personal computers or
smartphones, including resizing or cropping, quantization and compression, or common image
processing filters (e.g. Instagram’s photo filters).

![Illustrative examples of the 30 “basic” transformations used in our evaluation](/assets/notes/stay-aware-of-ai-generated-content/common-transformations.png)
*Illustrative examples of the 30 “basic” transformations used in our evaluation*

The encoder learns to spread watermark across the whole image, rather than placing it in the
vulnerable area, while the decoder learns to recognize that watermark even when parts of it are
damaged. This makes the watermark redundant and distributed, so losing some pixels or changing
patterns does not ease the overall watermark.

## Stay aware

Overall, SynthID is a testament to the fact that researchers are genuinely concerned about internet
is flooded with AI content.

But all this stuff is so technical, I can't imagine how we will survive on the internet in the
future when there are nothing but generated content. Will we have to *pay* for
*organic content*, and would we do it? How can you trust anything on the internet in 5 years?

Human nature is remarkably adaptable, we'll all learn to thrive within it.
